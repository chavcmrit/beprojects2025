# -*- coding: utf-8 -*-
"""ICH_Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1K2vmPpp2Fi2dr0CKMLciMrBaejetF3aV
"""

# Commented out IPython magic to ensure Python compatibility.
try:
    import monai
except ImportError:
    !pip install -q "monai-weekly[pillow, tqdm]"
    import monai

try:
    import matplotlib
except ImportError:
    !pip install -q matplotlib
    import matplotlib

# %matplotlib inline

import logging
import numpy as np
import os
from pathlib import Path
import sys
import tempfile
import torch

from sklearn.model_selection import train_test_split
from torchvision import datasets, transforms
from torch.utils.data import Subset

from monai.apps import MedNISTDataset
from monai.config import print_config
from monai.data import DataLoader
from monai.engines import SupervisedTrainer
from monai.handlers import StatsHandler
from monai.inferers import SimpleInferer
from monai.networks import eval_mode
#from monai.networks.nets import densenet121
from monai.networks.nets import Densenet169
from monai.networks.nets import EfficientNet
from monai.transforms import LoadImageD, EnsureChannelFirstD, ScaleIntensityD, Compose
import torch.nn as nn
import torch.optim as optim
from torch.utils.tensorboard import SummaryWriter
from torch.cuda.amp import autocast, GradScaler
from torch.optim.lr_scheduler import StepLR
import shutil
import tempfile
import matplotlib.pyplot as plt
import PIL
import torch
from torch.utils.tensorboard import SummaryWriter
import numpy as np
from sklearn.metrics import classification_report
from monai.transforms import Compose, LoadImaged, ToTensord, Lambda
from monai.apps import download_and_extract
from monai.config import print_config
from monai.data import decollate_batch, DataLoader
from monai.metrics import ROCAUCMetric
from monai.networks.nets import DenseNet121
from monai.transforms import (
    Activations,
    EnsureChannelFirst,
    AsDiscrete,
    Compose,
    LoadImage,
    RandFlip,
    RandRotate,
    RandZoom,
    ScaleIntensity,
)
from monai.utils import set_determinism
from google.colab import drive
from monai.visualize import GradCAM

print_config()

import os
import monai
from monai.apps import download_and_extract

root_dir="/content/"
resource = "https://drive.google.com/uc?id=1PEFWn3JpKWFxhu20Bh7Mbb5tn-yULLV_"
md5 = ""
compressed_file = os.path.join(root_dir, "sorted1.zip")
data_dir = os.path.join(root_dir, "sorted")
print(data_dir)
if not os.path.exists(data_dir):
    os.mkdir(os.path.join(root_dir,"sorted"))
    download_and_extract(resource, compressed_file, root_dir)

from zipfile import ZipFile
with ZipFile("/content/sorted1.zip", 'r') as zObject:
  zObject.extractall(path="/content")

from PIL import Image
import os

def resize_images(directory, target_size=(128, 128)):
    """Resizes all images in a directory to a target size."""
    for filename in os.listdir(directory):
        if filename.endswith(".jpg") or filename.endswith(".png"):  # Adjust file extensions if needed
            filepath = os.path.join(directory, filename)
            try:
                img = Image.open(filepath)
                img = img.resize(target_size, Image.Resampling.LANCZOS)  # High-quality resampling
                # print(img.mode)
                if img.mode == "RGBA":
                    imgmode = "RGB"
                    print(filepath)
                img.save(filepath)
            except IOError:
                print(f"Cannot resize '{filepath}'")

# Get the parent directory path
parent_directory = data_dir  # Update with your actual parent directory

# Resize images in folder "0"
resize_images(os.path.join(parent_directory, "0"))

# Resize images in folder "1"
resize_images(os.path.join(parent_directory, "1"))

print("Images resized successfully!")

print(data_dir)
# os.rmdir(os.path.join(data_dir,".ipynb_checkpoints"))
class_names = sorted(x for x in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, x)))
num_class = len(class_names)
image_files = [
    [os.path.join(data_dir, class_names[i], x) for x in os.listdir(os.path.join(data_dir, class_names[i]))]
    for i in range(num_class)
]
num_each = [len(image_files[i]) for i in range(num_class)]
image_files_list = []
image_class = []
for i in range(num_class):
    image_files_list.extend(image_files[i])
    image_class.extend([i] * num_each[i])
num_total = len(image_class)
image_width, image_height = PIL.Image.open(image_files_list[0]).size

print(f"Total image count: {num_total}")
print(f"Image dimensions: {image_width} x {image_height}")
print(f"Label names: {class_names}")
print(f"Label counts: {num_each}")

plt.subplots(3, 3, figsize=(8, 8))
for i, k in enumerate(np.random.randint(num_total, size=9)):
    im = PIL.Image.open(image_files_list[k])
    arr = np.array(im)
    plt.subplot(3, 3, i + 1)
    plt.xlabel(class_names[image_class[k]])
    plt.imshow(arr, cmap="gray", vmin=0, vmax=255)
plt.tight_layout()
plt.show()

val_frac = 0.1
test_frac = 0.1
length = len(image_files_list)
indices = np.arange(length)
np.random.shuffle(indices)

test_split = int(test_frac * length)
val_split = int(val_frac * length) + test_split
test_indices = indices[:test_split]
val_indices = indices[test_split:val_split]
train_indices = indices[val_split:]

train_x = [image_files_list[i] for i in train_indices]
train_y = [image_class[i] for i in train_indices]
val_x = [image_files_list[i] for i in val_indices]
val_y = [image_class[i] for i in val_indices]
test_x = [image_files_list[i] for i in test_indices]
test_y = [image_class[i] for i in test_indices]
print(type(train_y))
print(np.shape(train_y))
print(f"Training count: {len(train_x)}, Validation count: " f"{len(val_x)}, Test count: {len(test_x)}")

train_transforms = Compose(
    [
        LoadImage(image_only=True),
        EnsureChannelFirst(),
        ScaleIntensity(),
        RandRotate(range_x=np.pi / 12, prob=0.5, keep_size=True),
        RandFlip(spatial_axis=0, prob=0.5),
        RandZoom(min_zoom=0.9, max_zoom=1.1, prob=0.5),
    ]
)

val_transforms = Compose([LoadImage(image_only=True), EnsureChannelFirst(), ScaleIntensity()])

y_pred_trans = Compose([Activations(softmax=True)])
y_trans = Compose([AsDiscrete(to_onehot=num_class)])

class MedNISTDataset(torch.utils.data.Dataset):
    def __init__(self, image_files, labels, transforms):
        self.image_files = image_files
        self.labels = labels
        self.transforms = transforms

    def __len__(self):
        return len(self.image_files)

    def __getitem__(self, index):
        return self.transforms(self.image_files[index]), self.labels[index]


train_ds = MedNISTDataset(train_x, train_y, train_transforms)
train_loader = DataLoader(train_ds, batch_size=16, shuffle=True, num_workers=2)

val_ds = MedNISTDataset(val_x, val_y, val_transforms)
val_loader = DataLoader(val_ds, batch_size=16, num_workers=2)

test_ds = MedNISTDataset(test_x, test_y, val_transforms)
test_loader = DataLoader(test_ds, batch_size=16, num_workers=2)

for i, (images, labels) in enumerate(train_loader):
    print(i)
    print(type(labels))
    print(np.shape(labels))
    print(type(images))
    print(np.shape(images))

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

'''model = EfficientNet(
    blocks_args_str=[
    "r1_k3_s1_e1_i32_o16",
    "r2_k3_s2_e6_i16_o24",
    "r2_k5_s2_e6_i24_o40",
    "r3_k3_s2_e6_i40_o80",
    "r3_k5_s1_e6_i80_o112",
    "r4_k5_s2_e6_i112_o192",
    "r1_k3_s1_e6_i192_o320",
],  # Specify the variant, e.g., 'efficientnet-b0', 'efficientnet-b1', etc.
    spatial_dims=2,
    in_channels=3,
    num_classes=2,  # Set this to the number of classes in your dataset
    width_coefficient=1.0,  # For EfficientNet-B0, default value is 1.0
    depth_coefficient=1.0,  # For EfficientNet-B0, default value is 1.0
    dropout_rate=0.2,  # Controls dropout for regularization
    image_size=224,  # Adjust based on your input image size
).to(device)'''
model = Densenet169(spatial_dims=2, in_channels=3, out_channels=num_class).to(device)
loss_function = torch.nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), 1e-5)
max_epochs = 5
val_interval = 1
auc_metric = ROCAUCMetric()

best_metric = -1
best_metric_epoch = -1
epoch_loss_values = []
metric_values = []
writer = SummaryWriter()

# Learning rate scheduler: reduce LR every 10 epochs by a factor of 0.1
scheduler = StepLR(optimizer, step_size=10, gamma=0.1)

# Early stopping parameters
patience = 5
no_improve = 0

# For mixed precision training
scaler = GradScaler()

def train_one_epoch(model, loader, optimizer, loss_function, device, epoch, writer, scaler, max_grad_norm=1.0):
    model.train()
    epoch_loss = 0
    step = 0
    total_steps = len(loader)

    for batch_data in loader:
        step += 1
        # Assuming batch_data is a tuple/list with (inputs, labels)
        inputs, labels = batch_data[0].to(device), batch_data[1].to(device)
        optimizer.zero_grad()

        # Mixed precision forward pass
        with autocast():
            outputs = model(inputs)
            loss = loss_function(outputs, labels)

        # Backward pass with gradient scaling and clipping
        scaler.scale(loss).backward()
        scaler.unscale_(optimizer)
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)
        scaler.step(optimizer)
        scaler.update()

        epoch_loss += loss.item()
        print(f"Step [{step}/{total_steps}], train_loss: {loss.item():.4f}")
        writer.add_scalar("train_loss", loss.item(), total_steps * epoch + step)

    avg_loss = epoch_loss / step
    return avg_loss

def validate(model, loader, device, auc_metric, y_trans, y_pred_trans):
    model.eval()
    with torch.no_grad():
        # Containers for predictions and ground-truth labels
        y_pred_all = torch.tensor([], dtype=torch.float32, device=device)
        y_true_all = torch.tensor([], dtype=torch.long, device=device)

        for val_data in loader:
            val_images, val_labels = val_data[0].to(device), val_data[1].to(device)
            outputs = model(val_images)
            y_pred_all = torch.cat([y_pred_all, outputs], dim=0)
            y_true_all = torch.cat([y_true_all, val_labels], dim=0)

        # Transform predictions and ground truth as required by your AUC metric
        y_onehot = [y_trans(i) for i in decollate_batch(y_true_all, detach=False)]
        y_pred_act = [y_pred_trans(i) for i in decollate_batch(y_pred_all)]

        auc_metric(y_pred_act, y_onehot)
        auc_result = auc_metric.aggregate()
        auc_metric.reset()

        # Compute accuracy (for reporting)
        acc_metric = torch.eq(y_pred_all.argmax(dim=1), y_true_all).sum().item() / y_true_all.size(0)
    return auc_result, acc_metric

# Main training loop
for epoch in range(max_epochs):
    print("-" * 10)
    print(f"Epoch {epoch + 1}/{max_epochs}")

    # Train for one epoch
    epoch_loss = train_one_epoch(model, train_loader, optimizer, loss_function, device, epoch, writer, scaler)
    epoch_loss_values.append(epoch_loss)
    print(f"Epoch {epoch + 1} average loss: {epoch_loss:.4f}")

    # Run validation every 'val_interval' epochs
    if (epoch + 1) % val_interval == 0:
        auc_result, acc_metric = validate(model, val_loader, device, auc_metric, y_trans, y_pred_trans)
        metric_values.append(auc_result)
        writer.add_scalar("val_accuracy", acc_metric, epoch + 1)
        print(f"Epoch: {epoch + 1} | Current AUC: {auc_result:.4f} | Current Accuracy: {acc_metric:.4f}")

        # Save model if validation AUC improves
        if auc_result >= best_metric:
            best_metric = auc_result
            best_metric_epoch = epoch + 1
            torch.save(model.state_dict(), os.path.join(data_dir, "best_metric_model.pth"))
            print("Saved new best metric model")
            no_improve = 0  # reset early stopping counter
        else:
            no_improve += 1
            if no_improve >= patience:
                print("No improvement for several epochs, stopping early.")
                break

    # Step the learning rate scheduler at the end of the epoch
    scheduler.step()

print(f"Training completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}")
writer.close()

plt.figure("train", (12, 6))
plt.subplot(1, 2, 1)
plt.title("Epoch Average Loss")
x = [i + 1 for i in range(len(epoch_loss_values))]
y = epoch_loss_values
plt.xlabel("epoch")
plt.plot(x, y)
plt.subplot(1, 2, 2)
plt.title("Val AUC")
x = [val_interval * (i + 1) for i in range(len(metric_values))]
y = metric_values
plt.xlabel("epoch")
plt.plot(x, y)
plt.show()

model.load_state_dict(torch.load(os.path.join(data_dir, "best_metric_model.pth")))
model.eval()
y_true = []
y_pred = []
with torch.no_grad():
    for test_data in test_loader:
        test_images, test_labels = (
            test_data[0].to(device),
            test_data[1].to(device),
        )
        pred = model(test_images).argmax(dim=1)
        for i in range(len(pred)):
            y_true.append(test_labels[i].item())
            y_pred.append(pred[i].item())

print(classification_report(y_true, y_pred, target_names=class_names, digits=4))

from monai.transforms import Compose, LoadImage, EnsureChannelFirst, ScaleIntensity
import torch
import os

# Path to the image
image_path = "/content/sorted/1/089.png"

# Define transforms
the_transforms = Compose([
    LoadImage(image_only=True),  # Load the image
    EnsureChannelFirst(),       # Convert to channels-first format
    ScaleIntensity()            # Normalize pixel intensities
])


# Apply transformations
transformed_image = the_transforms(image_path)  # Output: 3D tensor [channels, height, width]

    # Add a batch dimension
transformed_image = torch.unsqueeze(transformed_image, 0).to(torch.float32)  # Shape: [1, channels, height, width]

    # Load the model
model.load_state_dict(torch.load(os.path.join(data_dir, "best_metric_model.pth")))
model.eval()

    # Perform inference
with torch.no_grad():

    output = model(transformed_image).argmax(dim=1)
    print(output)

# Replace all in-place ReLU operations with out-of-place ReLU
def replace_relu_with_out_of_place(model):
    for name, module in model.named_children():
        if isinstance(module, torch.nn.ReLU) and module.inplace:
            setattr(model, name, torch.nn.ReLU(inplace=False))
        else:
            replace_relu_with_out_of_place(module)  # Recursively check submodules

replace_relu_with_out_of_place(model)

target_layer = "features.norm5"

# Initialize Grad-CAM
cam = GradCAM(
    nn_module=model,
    target_layers=[target_layer],
)

# Pass the input image through Grad-CAM
# `image_tensor` should have the shape [Batch, Channels, Height, Width]
heatmap = cam(x=transformed_image, class_idx=1)  # Assuming class 1 corresponds to ICH

# Visualize the Heatmap
heatmap = heatmap[0, 0].cpu().detach().numpy()  # Take the first sample and first channel

# Plot the Heatmap
plt.imshow(heatmap, cmap="jet")
plt.colorbar()
plt.title("Grad-CAM Heatmap")
plt.show()

import cv2

# Generate Grad-CAM Heatmap
heatmap = cam(x=transformed_image, class_idx=1)
heatmap = heatmap[0, 0].cpu().detach().numpy()

# Convert transformed_image back to displayable format (numpy array for visualization)
transformed_image_display = transformed_image[0].cpu().numpy()  # Remove batch dimension
transformed_image_display = np.transpose(transformed_image_display, (1, 2, 0))  # [C, H, W] -> [H, W, C]
transformed_image_display = (transformed_image_display - transformed_image_display.min()) / (
    transformed_image_display.max() - transformed_image_display.min()
)  # Normalize to [0, 1] for display purposes

# Resize heatmap to match transformed_image dimensions
heatmap_resized = cv2.resize(heatmap, (transformed_image_display.shape[1], transformed_image_display.shape[0]))

# Overlay Heatmap
overlay = cv2.applyColorMap((heatmap_resized * 255).astype(np.uint8), cv2.COLORMAP_JET)  # Apply colormap
overlay = cv2.cvtColor(overlay, cv2.COLOR_BGR2RGB)  # Convert BGR (OpenCV) to RGB
overlay = (0.4 * overlay / 255.0 + 0.6 * transformed_image_display)  # Blend with transformed_image

# Plot the overlay
plt.figure(figsize=(10, 10))
plt.imshow(overlay)
plt.axis("off")
plt.title("Grad-CAM Heatmap Overlay")
plt.show()
